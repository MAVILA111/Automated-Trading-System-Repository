In this first document, we will resume the principal ideas for Reinforcement Learning applied to Economic System Decisions.
The first approach is by the book Reinforcement Learning: An Introduction, Richard S. Sutton et al.
"...the distinction between problems and solution methods is very important in reinforcement learning"
" We use for RL the framework of dynamical system theory. It is part of optimal control of incompletely-known Markov decision processes."
Partially Observed Markov Decision Process POMPD
En un POMDP, un agente toma decisiones en un entorno donde el estado real no es completamente visible, sino que se obtiene a través de observaciones incompletas o ruidosas. Esto introduce incertidumbre en el proceso de toma de decisiones, ya que el agente debe inferir el estado actual en función de las observaciones y tomar decisiones óptimas teniendo en cuenta esta incertidumbre.
La teoría de POMDP proporciona un marco matemático para modelar estas situaciones y encontrar políticas óptimas que maximicen las recompensas esperadas a largo plazo. Un POMDP se define por los siguientes componentes:
Espacio de estados: representa los posibles estados en los que puede encontrarse el sistema. En el caso de la predicción del precio de las principales variables económicas, los estados podrían incluir diferentes niveles de dichas variables, riesgos u otros indicadores relevantes.
Espacio de acciones: son las decisiones que el agente puede tomar en cada estado. Por ejemplo, más o menos impuestos, más o menos tasa de interés, más o menos intervención en los niveles de tipo de cambio, etc.
Función de transición: describe la probabilidad de transición de un estado a otro dado una acción tomada por el agente. En el contexto de la predicción del estado de la economía, esto podría modelar cómo el sistema económico reacciona a diferentes acciones y eventos.
Función de observación: indica la probabilidad de observar ciertos valores o señales dadas las acciones y los estados reales. En nuestro caso, podría representar la relación entre las observaciones del entorno económico, como los datos históricos o indicadores técnicos, y el estado real del sistema económico.
Función de recompensa: asigna una recompensa a cada acción tomada en función del estado en el que se encuentra el sistema. En el caso de la predicción del precio de la evolución del sistema, la función de recompensa podría estar relacionada con la precisión de las predicciones de ingreso per cápita, u optimización de los o niveles de consumo.
El objetivo principal en un POMDP es encontrar una política óptima, que es una regla que indica qué acción tomar en cada estado observado para maximizar las recompensas esperadas a largo plazo. Sin embargo, la naturaleza parcialmente observada del problema introduce desafíos adicionales, ya que el agente debe inferir el estado actual basándose en las observaciones disponibles.
En el contexto de la predicción del precio de la situación económica, un POMDP se puede utilizar para modelar la toma de decisiones de un agente que intenta predecir y optimizar los movimientos del sistema.
